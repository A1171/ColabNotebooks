{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4MskyTHx++/B+HNmQoleq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A1171/ColabNotebooks/blob/main/ResNet1D_%D0%B4%D0%BB%D1%8F_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D1%85_%D1%80%D1%8F%D0%B4%D0%BE%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ztDaPUjyVoDS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#%tensorflow_version 1.x\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import math\n",
        "from sklearn.preprocessing import LabelBinarizer,StandardScaler,MinMaxScaler\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Res-net 1D\n",
        "class DBL(keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel, strides=1, batch_norm=True,l2Conv=0.0005):\n",
        "        super(DBL, self).__init__()\n",
        "        self.filters=filters\n",
        "        self.kernel_size=kernel\n",
        "        self.strides=strides\n",
        "        self.batch_norm=batch_norm\n",
        "        self.padding='same' if strides == 1 else 'valid'\n",
        "        self.ZeroPadding1D=layers.ZeroPadding1D(padding=1)\n",
        "        self.l2Conv=l2Conv\n",
        "        #print(self.padding)\n",
        "        self.Conv1D=layers.Conv1D(self.filters,self.kernel_size,strides=self.strides, padding=self.padding,use_bias=not self.batch_norm, kernel_regularizer=regularizers.l2(self.l2Conv))#\n",
        "        self.BatchNormalization=layers.BatchNormalization(epsilon=0.001)\n",
        "        self.LeakyReLU=layers.LeakyReLU(alpha=0.1)\n",
        "    def call(self, inputs):\n",
        "        if self.strides> 1 :\n",
        "          x = self.ZeroPadding1D(inputs)\n",
        "        else:\n",
        "          x = inputs\n",
        "        x = self.Conv1D(x)\n",
        "        if self.batch_norm:\n",
        "          x = self.BatchNormalization(x)\n",
        "          x = self.LeakyReLU(x)\n",
        "        return x\n",
        "class Res_unit(keras.layers.Layer):\n",
        "    def __init__(self, filters,l2Conv=0.0005):\n",
        "        super(Res_unit, self).__init__()\n",
        "        self.filters=filters\n",
        "        self.DBL1=DBL(filters // 2, kernel=1,l2Conv=l2Conv)\n",
        "        self.DBL2=DBL(filters, kernel=3,l2Conv=l2Conv)\n",
        "        self.add=layers.add\n",
        "    def call(self, inputs):\n",
        "      skip_connection = inputs\n",
        "      x = self.DBL1(inputs)\n",
        "      x = self.DBL2(x)\n",
        "      x = self.add([skip_connection , x])\n",
        "      return x\n",
        "class ResBlock(keras.layers.Layer):\n",
        "    def __init__(self, filters, blocks,l2Conv=0.0005):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.filters=filters\n",
        "        self.blocks=blocks\n",
        "        self.DBL=DBL(self.filters, kernel=3, strides=2,l2Conv=l2Conv)\n",
        "        self.ResBlocks=[Res_unit(self.filters,l2Conv=l2Conv) for i in range(self.blocks)]\n",
        "    def call(self, inputs):\n",
        "      #print(len(self.ResBlocks))\n",
        "      x = self.DBL(inputs)\n",
        "      for i in range(self.blocks):\n",
        "        #print(x.shape)\n",
        "        x = self.ResBlocks[i](x)\n",
        "      return x\n",
        "def create_ResNet_model(Shape1,Neurons,Filters,l2Conv=0.0005,OutActivation='softmax',OutNeurons=3):\n",
        "  inputs1 = keras.Input(shape=Shape1)\n",
        "  lambdaActivity1=0\n",
        "  lambdaActivity=0\n",
        "  l2Dense=0.001\n",
        "  l2ConvB=0.0005\n",
        "  l2DenseB=0.001\n",
        "  x = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs1)\n",
        "  x = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*8, blocks=8,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*16, blocks=8,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*32, blocks=4,l2Conv=l2Conv)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(Neurons, activation='tanh',kernel_regularizer=regularizers.l2(l2Dense),bias_regularizer=regularizers.l2(l2Dense),activity_regularizer=regularizers.l1(lambdaActivity1))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(OutNeurons, activation=OutActivation)(x)\n",
        "  return keras.Model(inputs=inputs1, outputs=x)\n",
        "def create_ResNet_short(Shape1,Neurons,Filters,l2Conv=0.0005,OutActivation='softmax',OutNeurons=3):\n",
        "  inputs1 = keras.Input(shape=Shape1)\n",
        "  lambdaActivity1=0\n",
        "  lambdaActivity=0\n",
        "  l2Dense=0.001\n",
        "  l2ConvB=0.0005\n",
        "  l2DenseB=0.001\n",
        "  x = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs1)\n",
        "  x = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*8, blocks=3,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*16, blocks=3,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*32, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(Neurons, activation='tanh',kernel_regularizer=regularizers.l2(l2Dense),bias_regularizer=regularizers.l2(l2Dense),activity_regularizer=regularizers.l1(lambdaActivity1))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(OutNeurons, activation=OutActivation)(x)\n",
        "  return keras.Model(inputs=inputs1, outputs=x)\n",
        "def create_ResNet_short3In(Shape1,Shape2,Shape3,Neurons,Filters,l2Conv=0.0005,OutActivation='softmax',OutNeurons=3):\n",
        "  inputs1 = keras.Input(shape=Shape1)\n",
        "  inputs2 = keras.Input(shape=Shape2)\n",
        "  inputs3 = keras.Input(shape=Shape3)\n",
        "  lambdaActivity1=0\n",
        "  lambdaActivity=0\n",
        "  l2Dense=0.001\n",
        "  l2ConvB=0.0005\n",
        "  l2DenseB=0.001\n",
        "  x = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs1)\n",
        "  x = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*8, blocks=3,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*16, blocks=3,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*32, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x1 = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs2)\n",
        "  x1 = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*8, blocks=3,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*16, blocks=3,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*32, blocks=2,l2Conv=l2Conv)(x1)\n",
        "  x1 = layers.Flatten()(x1)\n",
        "  x2 = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs3)\n",
        "  x2 = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*8, blocks=3,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*16, blocks=3,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*32, blocks=2,l2Conv=l2Conv)(x2)\n",
        "  x2 = layers.Flatten()(x2)\n",
        "  x = layers.Concatenate()([x,x1,x2])\n",
        "  x = layers.Dense(Neurons, activation='tanh',kernel_regularizer=regularizers.l2(l2Dense),bias_regularizer=regularizers.l2(l2Dense),activity_regularizer=regularizers.l1(lambdaActivity1))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(OutNeurons, activation=OutActivation)(x)\n",
        "  return keras.Model(inputs=[inputs1,inputs2,inputs3], outputs=x)\n",
        "\n",
        "def create_ResNet_Vshort3In(Shape1,Shape2,Shape3,Neurons,Filters,l2Conv=0.0005,OutActivation='softmax',OutNeurons=3):\n",
        "  inputs1 = keras.Input(shape=Shape1)\n",
        "  inputs2 = keras.Input(shape=Shape2)\n",
        "  inputs3 = keras.Input(shape=Shape3)\n",
        "  lambdaActivity1=0\n",
        "  lambdaActivity=0\n",
        "  l2Dense=0.001\n",
        "  l2ConvB=0.0005\n",
        "  l2DenseB=0.001\n",
        "  x = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs1)\n",
        "  x = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*4, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*8, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*16, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*32, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x1 = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs2)\n",
        "  x1 = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*4, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*8, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*16, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*32, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = layers.Flatten()(x1)\n",
        "  x2 = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs3)\n",
        "  x2 = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*4, blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*8, blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*16, blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=Filters*32, blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = layers.Flatten()(x2)\n",
        "  x = layers.Concatenate()([x,x1,x2])\n",
        "  x = layers.Dense(Neurons, activation='tanh',kernel_regularizer=regularizers.l2(l2Dense),bias_regularizer=regularizers.l2(l2Dense),activity_regularizer=regularizers.l1(lambdaActivity1))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(OutNeurons, activation=OutActivation)(x)\n",
        "  return keras.Model(inputs=[inputs1,inputs2,inputs3], outputs=x)\n",
        "\n",
        "def create_ResNet_short4In(Shape1,Shape2,Shape3,Shape4,Neurons,Filters,l2Conv=0.0005,OutActivation='softmax',OutNeurons=3):\n",
        "  inputs1 = keras.Input(shape=Shape1)\n",
        "  inputs2 = keras.Input(shape=Shape2)\n",
        "  inputs3 = keras.Input(shape=Shape3)\n",
        "  inputs4 = keras.Input(shape=Shape4)\n",
        "  lambdaActivity1=0\n",
        "  lambdaActivity=0\n",
        "  l2Dense=0.001\n",
        "  l2ConvB=0.0005\n",
        "  l2DenseB=0.001\n",
        "  x = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs1)\n",
        "  x = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*8, blocks=3,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*16, blocks=3,l2Conv=l2Conv)(x)\n",
        "  x = ResBlock(filters=Filters*32, blocks=2,l2Conv=l2Conv)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x1 = DBL(filters=Filters, kernel=3,l2Conv=l2Conv)(inputs2)\n",
        "  x1 = ResBlock(filters=Filters*2, blocks=1,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*4, blocks=2,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*8, blocks=3,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*16, blocks=3,l2Conv=l2Conv)(x1)\n",
        "  x1 = ResBlock(filters=Filters*32, blocks=2,l2Conv=l2Conv)(x1)\n",
        "  x1 = layers.Flatten()(x1)\n",
        "  x2 = DBL(filters=int(Filters*0.7), kernel=3,l2Conv=l2Conv)(inputs3)\n",
        "  x2 = ResBlock(filters=int(Filters*2*0.7), blocks=1,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=int(Filters*4*0.7), blocks=2,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=int(Filters*8*0.7), blocks=3,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=int(Filters*16*0.7), blocks=3,l2Conv=l2Conv)(x2)\n",
        "  x2 = ResBlock(filters=int(Filters*32*0.7), blocks=2,l2Conv=l2Conv)(x2)\n",
        "  x2 = layers.Flatten()(x2)\n",
        "  x3 = DBL(filters=int(Filters*0.5), kernel=3,l2Conv=l2Conv)(inputs4)\n",
        "  x3 = ResBlock(filters=int(Filters*2*0.5), blocks=1,l2Conv=l2Conv)(x3)\n",
        "  x3 = ResBlock(filters=int(Filters*4*0.5), blocks=2,l2Conv=l2Conv)(x3)\n",
        "  x3 = ResBlock(filters=int(Filters*8*0.5), blocks=3,l2Conv=l2Conv)(x3)\n",
        "  x3 = ResBlock(filters=int(Filters*16*0.5), blocks=3,l2Conv=l2Conv)(x3)\n",
        "  x3 = ResBlock(filters=int(Filters*32*0.5), blocks=2,l2Conv=l2Conv)(x3)\n",
        "  x3 = layers.Flatten()(x3)\n",
        "  x = layers.Concatenate()([x,x1,x2,x3])\n",
        "  x = layers.Dense(Neurons, activation='tanh',kernel_regularizer=regularizers.l2(l2Dense),bias_regularizer=regularizers.l2(l2Dense),activity_regularizer=regularizers.l1(lambdaActivity1))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(OutNeurons, activation=OutActivation)(x)\n",
        "  return keras.Model(inputs=[inputs1,inputs2,inputs3,inputs4], outputs=x)\n"
      ],
      "metadata": {
        "id": "ooBfEml-VxaJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Функция оценки результата\n",
        "def TradeResultMdf(Pred,ProfitArr,Border=[0,0,0]):\n",
        "  Volume=0\n",
        "  VolumeBuy=0\n",
        "  VolumeSell=0\n",
        "  Profit=0\n",
        "  WinVolumeBuy=0\n",
        "  LossVolumeBuy=0\n",
        "  WinVolumeSell=0\n",
        "  LossVolumeSell=0\n",
        "  BuyArr=Pred[:,0]-Border[0]\n",
        "  SellArr=Pred[:,2]-Border[2]\n",
        "  BuyArr1=np.logical_and(BuyArr>Pred[:,1],BuyArr>Pred[:,2])\n",
        "  SellArr1=np.logical_and(SellArr>Pred[:,1],SellArr>Pred[:,0])\n",
        "  VolumeBuy=np.sum(np.abs(ProfitArr[:,0][BuyArr1]))\n",
        "  ProfitBuy=np.sum(ProfitArr[:,0][BuyArr1])\n",
        "  VolumeSell=np.sum(np.abs(ProfitArr[:,1][SellArr1]))\n",
        "  ProfitSell=np.sum(ProfitArr[:,1][SellArr1])\n",
        "  VolumeAll=np.sum(np.abs(ProfitArr))/2\n",
        "  Recall=(VolumeBuy+VolumeSell)/VolumeAll\n",
        "  del BuyArr\n",
        "  del SellArr\n",
        "  del BuyArr1\n",
        "  del SellArr1\n",
        "  return ProfitBuy,ProfitSell, VolumeBuy,VolumeSell, Recall\n",
        "#Функция расчета доходности от границы классификации\n",
        "def ClassBorderProfit(Pred,ProfitArr,STDBorders,AddSTDCorrection=True):\n",
        "  NumOuts2=Pred.shape[1]//NClasses\n",
        "  NumSTDBorders=len(STDBorders)\n",
        "  PFArr=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  RecallArr=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  PFArrBuy=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  PFArrSell=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  VolumeBuy=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  VolumeSell=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  ProfitBuy=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  ProfitSell=np.zeros((NumSTDBorders,NumOuts2))\n",
        "  if(AddSTDCorrection):\n",
        "    Pred1=(Pred-Pred.mean(axis=0))/Pred.std(axis=0)\n",
        "  else:\n",
        "    Pred1=Pred\n",
        "  for i in range(NumOuts2):\n",
        "    for j in range(NumSTDBorders):\n",
        "      ProfitBuy1_1,ProfitSell1_1, VolumeBuy1_1,VolumeSell1_1, Recall1_1=TradeResultMdf(Pred1,ProfitArr,Border=[STDBorders[j],STDBorders[j],STDBorders[j]])\n",
        "      RecallArr[j,i]=Recall1_1\n",
        "      VolumeBuy[j,i]=VolumeBuy1_1\n",
        "      VolumeSell[j,i]=VolumeBuy1_1\n",
        "      ProfitBuy[j,i]=ProfitBuy1_1\n",
        "      ProfitSell[j,i]=ProfitSell1_1\n",
        "      \n",
        "      if(VolumeBuy1_1+VolumeSell1_1>0):\n",
        "        PFArr[j,i]=(ProfitBuy1_1+ProfitSell1_1)/(VolumeBuy1_1+VolumeSell1_1)\n",
        "      else:\n",
        "        if(j>0):\n",
        "          PFArr[j,i]=PFArr[j-1,i]\n",
        "        else:\n",
        "          PFArr[j,i]=0\n",
        "      if(VolumeBuy1_1>0):\n",
        "        PFArrBuy[j,i]=ProfitBuy1_1/VolumeBuy1_1\n",
        "      else:\n",
        "        if(j>0):\n",
        "          PFArrBuy[j,i]=PFArrBuy[j-1,i]\n",
        "        else:\n",
        "          PFArrBuy[j,i]=0\n",
        "      if(VolumeSell1_1>0):\n",
        "        PFArrSell[j,i]=ProfitSell1_1/VolumeSell1_1\n",
        "      else:\n",
        "        if(j>0):\n",
        "          PFArrSell[j,i]=PFArrSell[j-1,i]\n",
        "        else:\n",
        "          PFArrSell[j,i]=0\n",
        "  del Pred1\n",
        "  gc.collect()\n",
        "  return PFArr,RecallArr,PFArrBuy,PFArrSell,VolumeBuy,VolumeSell,ProfitBuy,ProfitSell\n"
      ],
      "metadata": {
        "id": "E5gdJQNxVxdP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше куча процедур для тестирования к Res-net не относится"
      ],
      "metadata": {
        "id": "kcEPcaYJdZrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomCallback(keras.callbacks.Callback):\n",
        "    def __init__(self,STDBorders,ChartTestList,ChartValList,EpochStep=1,BatchStep=1):\n",
        "      self.STDBorders=STDBorders\n",
        "      self.ChartTestList=ChartTestList\n",
        "      self.ChartValList=ChartValList\n",
        "      self.EpochStep=EpochStep\n",
        "      self.BatchStep=BatchStep\n",
        "                 \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      if(epoch%self.EpochStep==0):\n",
        "          pred2=[]\n",
        "          pred3=[]\n",
        "          Profit2=[]\n",
        "          Profit3=[]\n",
        "          for i in range(0,test_datagen_est.__len__(),self.BatchStep):\n",
        "              Batch=test_datagen_est[i]\n",
        "              if(len(pred2)==0):\n",
        "                pred2=self.model.predict(Batch[0],verbose=0)\n",
        "                Profit2=Batch[2]\n",
        "              else:\n",
        "                pred2=np.vstack((pred2,self.model.predict(Batch[0],verbose=0)))\n",
        "                Profit2=np.vstack((Profit2,Batch[2]))\n",
        "          for i in range(0,val_datagen_est.__len__(),self.BatchStep):\n",
        "              Batch=val_datagen_est[i]\n",
        "              if(len(pred3)==0):\n",
        "                pred3=self.model.predict(Batch[0],verbose=0)\n",
        "                Profit3=Batch[2]\n",
        "              else:\n",
        "                pred3=np.vstack((pred3,self.model.predict(Batch[0],verbose=0)))\n",
        "                Profit3=np.vstack((Profit3,Batch[2]))\n",
        "          gc.collect()\n",
        "          PFArr1,RecallArr1,PFArrBuy1,PFArrSell1,VolumeBuy1,VolumeSell1,ProfitBuy1,ProfitSell1=ClassBorderProfit(pred2,Profit2,self.STDBorders,AddSTDCorrection=True)\n",
        "          PFArr2,RecallArr2,PFArrBuy2,PFArrSell2,VolumeBuy2,VolumeSell2,ProfitBuy2,ProfitSell2=ClassBorderProfit(pred3,Profit3,self.STDBorders,AddSTDCorrection=True)\n",
        "          self.ChartTestList.append([PFArr1[:,0],RecallArr1[:,0],(VolumeBuy1+VolumeSell1)[:,0]])\n",
        "          self.ChartValList.append([PFArr2[:,0],RecallArr2[:,0],(VolumeBuy2+VolumeSell2)[:,0]])\n",
        "          print()\n",
        "          print(\"Check std=\",self.STDBorders,\"P\",[int(PFArr1[Item,0]*1000)/10 for Item in range(len(self.STDBorders))],[int(PFArr2[Item,0]*1000)/10 for Item in range(len(self.STDBorders))],\"PM\",[int((PFArr1[Item,0]+PFArr2[Item,0])*1000)/10/2 for Item in range(len(self.STDBorders))],\"R\",[int(RecallArr1[Item,0]*1000)/10 for Item in range(len(self.STDBorders))],[int(RecallArr2[Item,0]*1000)/10 for Item in range(len(self.STDBorders))])\n",
        "      \n",
        "custom_objects = {\"MyCustomCallback\":MyCustomCallback}"
      ],
      "metadata": {
        "id": "2WdsyKUDVxgg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Template51(y_data_train2):#4 периода TP=0.4 SL=0.2\n",
        "  if(y_data_train2[24]==1 and y_data_train2[4]>-1 and y_data_train2[3]>-1 and y_data_train2[2]>-1):\n",
        "    return 1\n",
        "  if(y_data_train2[24]==-1 and y_data_train2[4]<1 and y_data_train2[3]<1 and y_data_train2[2]<1):# and y_data_train2[43]==-1\n",
        "    return -1\n",
        "  return 0\n",
        "def Template51Profit(y_data_train2):#4 периода TP=0.4 SL=0.2\n",
        "  BuyPr=y_data_train2[34]\n",
        "  if(BuyPr<-0.5):BuyPr=-0.5\n",
        "  SellPr=-y_data_train2[34]\n",
        "  if(SellPr<-0.5):SellPr=-0.5\n",
        "  return np.array([BuyPr,SellPr])"
      ],
      "metadata": {
        "id": "O74TPMYQVxjR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetWeightMatrixFromDatagen(Datagen,Step=5):\n",
        "  y_in_data_tr2=[]\n",
        "  for i in range(0,train_datagen.__len__(),5):\n",
        "    if(len(y_in_data_tr2)==0):\n",
        "      y_in_data_tr2=train_datagen[i][1]\n",
        "    else:\n",
        "      y_in_data_tr2=np.vstack((y_in_data_tr2,train_datagen[i][1]))\n",
        "  Argmax_y=np.argmax(y_in_data_tr2,axis=1)\n",
        "  WeightMatrix18List=[]\n",
        "  #print(y_in_data_tr2.shape,len(Argmax_y[Argmax_y==0]),len(Argmax_y[Argmax_y==1]))\n",
        "  for i in range(y_in_data_tr2.shape[1]):\n",
        "    WeightMatrix18List.append(1/len(Argmax_y[Argmax_y==i]))\n",
        "  WeightMatrix18List=np.array(WeightMatrix18List)\n",
        "  WeightMatrix18List=WeightMatrix18List/np.amax(WeightMatrix18List)\n",
        "  Multiplier=np.sum(1/WeightMatrix18List)/len(WeightMatrix18List)\n",
        "  WeightMatrix18List=WeightMatrix18List*Multiplier\n",
        "  WeightMatrix2=dict(enumerate(WeightMatrix18List.flatten(), 0))\n",
        "  del y_in_data_tr2\n",
        "  del Argmax_y\n",
        "  gc.collect()\n",
        "  return WeightMatrix2\n",
        "import gc\n",
        "class TMultiTF_Datagen2(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x_data_tr,y_in_data_tr,FeaturesLists,ScaleGroup,Binalizers,LenSeq,batch_size,TemplateFunction,ProfitFunction,TimeOut=False,UseDOW=False,GenerateProfitArr=False):\n",
        "        self.x_data_tr=x_data_tr\n",
        "        self.y_in_data_tr=y_in_data_tr\n",
        "        self.FeaturesLists=FeaturesLists\n",
        "        self.ScaleGroup=ScaleGroup\n",
        "        self.LenSeq=LenSeq\n",
        "        self.batch_size = batch_size\n",
        "        self.TimeOut=TimeOut\n",
        "        self.UseDOW=UseDOW\n",
        "        self.GenerateProfitArr=GenerateProfitArr\n",
        "        self.TemplateFunction=TemplateFunction\n",
        "        self.ProfitFunction=ProfitFunction\n",
        "        self.FeaturesSet=[]\n",
        "        self.Scallers=[]\n",
        "        BinalizerDOW,BinalizerHour,BinalizerMin,BinalizerRSI=Binalizers\n",
        "        if(not UseDOW):\n",
        "              if(x_data_tr.shape[0]>0):self.Time_Bin_tr=np.hstack((BinalizerHour.transform(np.array((x_data_tr[:,HourPos]+0.1),dtype=int)),BinalizerMin.transform(np.array((x_data_tr[:,MinPos]+0.1),dtype=int))))\n",
        "        else:\n",
        "              if(x_data_tr.shape[0]>0):self.Time_Bin_tr=np.hstack((BinalizerDOW.transform(np.array((x_data_tr[:,DOWPos]+0.1),dtype=int)),BinalizerHour.transform(np.array((x_data_tr[:,HourPos]+0.1),dtype=int)),BinalizerMin.transform(np.array((x_data_tr[:,MinPos]+0.1),dtype=int))))\n",
        "        for i in range(len(self.FeaturesLists)):\n",
        "          self.FeaturesSet.append(x_data_tr[:,self.FeaturesLists[i]])\n",
        "          if(ScaleGroup[i]<2):\n",
        "            self.Scallers.append([])\n",
        "          elif(ScaleGroup[i]==2):#minmax\n",
        "            self.Scallers.append(StandardScaler())\n",
        "            self.Scallers[-1].fit(self.FeaturesSet[-1])\n",
        "            self.FeaturesSet[-1]=self.Scallers[-1].transform(self.FeaturesSet[-1])\n",
        "          elif(ScaleGroup[i]==3):#std\n",
        "            self.Scallers.append(MinMaxScaler())\n",
        "            self.Scallers[-1].fit(self.FeaturesSet[-1])\n",
        "            self.FeaturesSet[-1]=self.Scallers[-1].transform(self.FeaturesSet[-1])\n",
        "\n",
        "        self.TrTestStart=(self.LenSeq+1)+1\n",
        "        self.TrainStop=len(self.x_data_tr)\n",
        "        gc.collect()\n",
        "        \n",
        "    def __len__(self):\n",
        "        #print(\"__len__\",self.TrTestStart,self.TrainStop, int(np.floor((self.TrainStop-self.TrTestStart) / self.batch_size)))\n",
        "        len1=int(np.floor((self.TrainStop-self.TrTestStart) / self.batch_size))\n",
        "        if(len1*self.batch_size<self.TrainStop-self.TrTestStart):\n",
        "          len1+=1\n",
        "        return len1\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        TrBunchStart=self.TrTestStart+idx*self.batch_size\n",
        "        TrBunchStop=TrBunchStart+self.batch_size\n",
        "        if(TrBunchStop>self.TrainStop):TrBunchStop=self.TrainStop\n",
        "        x_data_train_t1=[]\n",
        "        x_data_train_time=[]\n",
        "        y_in_data_train2=[]\n",
        "        SequencyLenP1=self.LenSeq\n",
        "        MiddleClass=NClasses//2\n",
        "        \n",
        "        for i in range(TrBunchStart+1,TrBunchStop+1,RecordsStep):\n",
        "          Record=[]\n",
        "          for j in range(len(self.FeaturesSet)):\n",
        "            Arr1=self.FeaturesSet[j]\n",
        "            Record.append(Arr1[i-SequencyLenP1:i].copy())\n",
        "            if(self.ScaleGroup[j]==1):\n",
        "              GroupMax=np.amax(Record[-1])\n",
        "              GroupMin=np.amin(Record[-1])\n",
        "              GroupStd1=Record[-1].std()\n",
        "              Div=(GroupMax-GroupMin)\n",
        "              if(Div<=0):Div=GroupStd1/10\n",
        "              if(Div<=0):Div=0.0001\n",
        "              Record[-1]=(Record[-1]-GroupMin)/Div\n",
        "          Record=np.hstack(Record)\n",
        "          x_data_train_t1.append(Record)\n",
        "          x_data_train_time.append(self.Time_Bin_tr[i-1].copy())\n",
        "          if(type(self.y_in_data_tr)!=type(None)):y_in_data_train2.append(self.y_in_data_tr[i-1])\n",
        "        x_data_train_t1=np.array(x_data_train_t1)\n",
        "        x_data_train_time=np.array(x_data_train_time)\n",
        "        if(type(self.y_in_data_tr)!=type(None)):y_in_data_train2=np.array(y_in_data_train2)\n",
        "        TemplTr=[]\n",
        "        TemplTrPr=[]\n",
        "        if(type(y_in_data_tr)!=type(None)):\n",
        "          for i in range(y_in_data_train2.shape[0]):\n",
        "            TemplTr.append(self.TemplateFunction(y_in_data_train2[i]))\n",
        "            TemplTrPr.append(self.ProfitFunction(y_in_data_train2[i]))\n",
        "        TemplTr=np.array(TemplTr)\n",
        "        TemplTrPr=np.array(TemplTrPr)\n",
        "\n",
        "        y_data_train_tpl=np.zeros((y_in_data_train2.shape[0],NClasses))\n",
        "        y_data_train_tpl[np.where(TemplTr==1),MiddleClass-1]=1\n",
        "        y_data_train_tpl[np.where(TemplTr==0),MiddleClass]=1\n",
        "        y_data_train_tpl[np.where(TemplTr==-1),MiddleClass+1]=1\n",
        "        if(NClasses>3):\n",
        "          y_data_train_tpl[np.where(TemplTr==2),MiddleClass-2]=1\n",
        "          y_data_train_tpl[np.where(TemplTr==-2),MiddleClass+2]=1\n",
        "        if(NClasses>5):\n",
        "          y_data_train_tpl[np.where(TemplTr==3),MiddleClass-3]=1\n",
        "          y_data_train_tpl[np.where(TemplTr==-3),MiddleClass+3]=1\n",
        "        \n",
        "        InputsList=[]\n",
        "        InputsList.append(x_data_train_t1)\n",
        "        if(self.TimeOut):\n",
        "          InputsList.append(x_data_train_time)\n",
        "        \n",
        "\n",
        "        if(len(InputsList)==1):\n",
        "          InputsList=InputsList[0]\n",
        "\n",
        "        gc.collect()\n",
        "        #print(InputsList[0].shape,InputsList[1].shape,y_data_train_tpl.shape)\n",
        "        \n",
        "        if(self.GenerateProfitArr):return (InputsList,y_data_train_tpl,TemplTrPr)\n",
        "        else:return (InputsList,y_data_train_tpl)\n"
      ],
      "metadata": {
        "id": "RPkJOLQIVxmL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-pnr3EMfHvI",
        "outputId": "d0f3688e-6545-43fd-81fe-4855e5f48631"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SequencyLen=32\n",
        "RecordsStep=1\n",
        "NClasses=3"
      ],
      "metadata": {
        "id": "guPDyC2ChXji"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HistoryFileDir=\"drive/My Drive/NN/DiplShares/\"\n",
        "#Загрузка массива данных и разбивка на выборки\n",
        "AdditNames=[\"SBER_M5_Linear5\"]\n",
        "TrainTestGap=SequencyLen+100\n",
        "trainPart=0.8\n",
        "testPart=0.1\n",
        "x_data_1 = np.loadtxt(HistoryFileDir+\"DataFileI1_\"+AdditNames[0]+'.txt')\n",
        "y_data_1 = np.loadtxt(HistoryFileDir+\"DataFileO1_\"+AdditNames[0]+'.txt')\n",
        "x_data_tr=x_data_1[:int(len(x_data_1)*trainPart)]\n",
        "x_data_test=x_data_1[int(len(x_data_1)*trainPart+TrainTestGap):int(len(x_data_1)*(trainPart+testPart)+TrainTestGap)]\n",
        "x_data_val=x_data_1[int(len(x_data_1)*(trainPart+testPart)+TrainTestGap*2):]\n",
        "y_in_data_tr=y_data_1[:int(len(x_data_1)*trainPart)]\n",
        "y_in_data_test=y_data_1[int(len(x_data_1)*trainPart+TrainTestGap):int(len(x_data_1)*(trainPart+testPart)+TrainTestGap)]\n",
        "y_in_data_val=y_data_1[int(len(x_data_1)*(trainPart+testPart)+TrainTestGap*2):]"
      ],
      "metadata": {
        "id": "qViwWvwjVxpI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Биналайзеры для временни"
      ],
      "metadata": {
        "id": "T9ED8aGo9A_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DOWPos=3\n",
        "HourPos=5\n",
        "MinPos=6\n",
        "BinalizerDOW=LabelBinarizer()\n",
        "BinalizerHour=LabelBinarizer()\n",
        "BinalizerMin=LabelBinarizer()\n",
        "BinalizerRSI=LabelBinarizer()\n",
        "BinalizerDOW.fit(np.array((x_data_tr[:,DOWPos]+0.1),dtype=int))\n",
        "BinalizerHour.fit(np.array((x_data_tr[:,HourPos]+0.1),dtype=int))\n",
        "BinalizerMin.fit(np.array((x_data_tr[:,MinPos]+0.1),dtype=int))\n",
        "Binalizers=[BinalizerDOW,BinalizerHour,BinalizerMin,BinalizerRSI]"
      ],
      "metadata": {
        "id": "HEkZHCcWcnIu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adamopt=tf.keras.optimizers.Adam(learning_rate=0.0004, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "metadata": {
        "id": "3_Dpbztmcys5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создаем группы признаков. Данные будут масштабироваться целеком группами\n",
        "FeaturesLists=[[8,9,10,11],[12],[15,18,19,21]]\n",
        "#Выбираем способ масштабирования для каждой из групп\n",
        "#0 - без масштабирования\n",
        "#1 - Min/Max масштабирование целиком для группы\n",
        "#2 - Min/Max масштабирование отдельно для каждого признака\n",
        "#3 - Std масштабирование отдельно для каждого признака\n",
        "ScaleGroup=[1,1,2]\n",
        "#имена отобранных признаков для графиков\n",
        "Names123=[\"OM541\",\"HM541\",\"LM541\",\"CM541\",\"VM541\",\"1RSI14\",\"2RSI14\",\"3RSI3\",\"3RSI14\"]\n",
        "BatchSize=4096\n",
        "SequencyLen=32\n",
        "GenerateProfitArr=False\n",
        "train_datagen=TMultiTF_Datagen2(x_data_tr,y_in_data_tr,FeaturesLists,ScaleGroup,Binalizers,SequencyLen,BatchSize,Template51,Template51Profit,TimeOut=False,UseDOW=False,GenerateProfitArr=GenerateProfitArr)\n",
        "test_datagen=TMultiTF_Datagen2(x_data_test,y_in_data_test,FeaturesLists,ScaleGroup,Binalizers,SequencyLen,BatchSize,Template51,Template51Profit,TimeOut=False,UseDOW=False,GenerateProfitArr=GenerateProfitArr)\n",
        "val_datagen=TMultiTF_Datagen2(x_data_val,y_in_data_val,FeaturesLists,ScaleGroup,Binalizers,SequencyLen,BatchSize,Template51,Template51Profit,TimeOut=False,UseDOW=False,GenerateProfitArr=GenerateProfitArr)\n",
        "#datagen for profit check. It have 1 batch with full length and profit estimate arrays\n",
        "BatchSize=1024\n",
        "GenerateProfitArr=True\n",
        "train_datagen_est=TMultiTF_Datagen2(x_data_tr,y_in_data_tr,FeaturesLists,ScaleGroup,Binalizers,SequencyLen,BatchSize,Template51,Template51Profit,TimeOut=False,UseDOW=False,GenerateProfitArr=GenerateProfitArr)\n",
        "test_datagen_est=TMultiTF_Datagen2(x_data_test,y_in_data_test,FeaturesLists,ScaleGroup,Binalizers,SequencyLen,BatchSize,Template51,Template51Profit,TimeOut=False,UseDOW=False,GenerateProfitArr=GenerateProfitArr)\n",
        "val_datagen_est=TMultiTF_Datagen2(x_data_val,y_in_data_val,FeaturesLists,ScaleGroup,Binalizers,SequencyLen,BatchSize,Template51,Template51Profit,TimeOut=False,UseDOW=False,GenerateProfitArr=GenerateProfitArr)\n"
      ],
      "metadata": {
        "id": "W1mlKfrKcyx9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WeightMatrix2=GetWeightMatrixFromDatagen(train_datagen,Step=3)\n",
        "WeightMatrix2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOEQAOzPcnLY",
        "outputId": "5623c068-5506-428d-f52d-6e9ae297ecbf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 3.617461519051224, 1: 0.4112538278936007, 2: 3.4249537119990445}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Границы классификации для предварительной оценки доходности в калбеке\n",
        "STDBorders=[0,0.5,0.7,1,1.5,2]\n",
        "ChartTestList=[]\n",
        "ChartValList=[]\n",
        "EstimateCallback=MyCustomCallback(STDBorders,ChartTestList,ChartValList,EpochStep=1,BatchStep=2)\n",
        "model_10=create_ResNet_model(train_datagen[0][0][0].shape,20,8,l2Conv=0.0005,OutActivation='softmax',OutNeurons=3)\n",
        "model_10.compile(loss=\"categorical_crossentropy\",optimizer=adamopt,metrics=['accuracy','mae'])\n",
        "history1=model_10.fit(train_datagen,validation_data=test_datagen,callbacks=[EstimateCallback],class_weight=WeightMatrix2,epochs=10,verbose=1)#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn9xqDIvVxwr",
        "outputId": "beeadf1d-6e01-45a8-85ca-f04304c70297"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.9989 - accuracy: 0.3215 - mae: 0.4474\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [12.5, 11.5, 11.3, 9.4, 7.2, 9.8] [19.7, 19.8, 19.6, 17.7, 15.9, 13.6] PM [16.1, 15.65, 15.5, 13.55, 11.6, 11.7] R [67.2, 47.0, 39.5, 29.9, 17.4, 9.3] [68.2, 47.3, 39.7, 30.2, 18.0, 9.8]\n",
            "68/68 [==============================] - 293s 4s/step - loss: 2.9989 - accuracy: 0.3215 - mae: 0.4474 - val_loss: 2.6307 - val_accuracy: 0.0975 - val_mae: 0.4480\n",
            "Epoch 2/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.5228 - accuracy: 0.3181 - mae: 0.4470\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [16.2, 15.9, 16.5, 16.3, 17.3, 17.5] [16.3, 16.1, 15.3, 14.1, 12.0, 12.2] PM [16.3, 16.05, 15.9, 15.25, 14.7, 14.85] R [70.4, 48.4, 40.5, 30.0, 16.7, 9.0] [71.7, 49.4, 41.5, 31.2, 18.4, 10.0]\n",
            "68/68 [==============================] - 257s 4s/step - loss: 2.5228 - accuracy: 0.3181 - mae: 0.4470 - val_loss: 2.3790 - val_accuracy: 0.5011 - val_mae: 0.4415\n",
            "Epoch 3/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.3163 - accuracy: 0.2914 - mae: 0.4457\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [17.3, 18.4, 18.3, 18.5, 18.0, 15.6] [15.3, 15.3, 15.3, 13.6, 8.3, 6.5] PM [16.3, 16.9, 16.85, 16.1, 13.15, 11.1] R [70.4, 48.0, 40.4, 29.9, 17.1, 9.0] [71.5, 49.3, 41.7, 31.0, 17.3, 9.0]\n",
            "68/68 [==============================] - 269s 4s/step - loss: 2.3163 - accuracy: 0.2914 - mae: 0.4457 - val_loss: 2.1821 - val_accuracy: 0.5984 - val_mae: 0.4368\n",
            "Epoch 4/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.1522 - accuracy: 0.3547 - mae: 0.4410\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [15.6, 14.8, 15.2, 16.8, 17.5, 21.7] [17.5, 16.1, 15.8, 15.0, 14.3, 13.0] PM [16.55, 15.5, 15.5, 15.9, 15.9, 17.4] R [73.0, 52.3, 45.1, 35.2, 20.8, 11.2] [74.4, 52.8, 45.3, 35.1, 21.3, 11.2]\n",
            "68/68 [==============================] - 247s 4s/step - loss: 2.1522 - accuracy: 0.3547 - mae: 0.4410 - val_loss: 2.1286 - val_accuracy: 0.1031 - val_mae: 0.4564\n",
            "Epoch 5/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 2.0164 - accuracy: 0.2928 - mae: 0.4445\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [16.4, 16.6, 16.5, 17.4, 19.5, 20.8] [19.1, 18.8, 18.9, 18.6, 19.4, 17.9] PM [17.8, 17.75, 17.7, 18.0, 19.45, 19.4] R [71.3, 51.0, 44.1, 34.6, 21.8, 12.4] [72.4, 52.0, 44.7, 35.0, 21.9, 12.2]\n",
            "68/68 [==============================] - 248s 4s/step - loss: 2.0164 - accuracy: 0.2928 - mae: 0.4445 - val_loss: 2.0294 - val_accuracy: 0.1083 - val_mae: 0.4599\n",
            "Epoch 6/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.9051 - accuracy: 0.2994 - mae: 0.4441\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [17.7, 18.2, 18.8, 19.4, 21.3, 20.9] [18.7, 18.1, 18.7, 18.6, 16.3, 18.3] PM [18.2, 18.2, 18.75, 19.05, 18.85, 19.6] R [73.0, 52.6, 45.4, 35.2, 21.7, 12.3] [73.6, 52.8, 45.5, 35.1, 21.6, 12.3]\n",
            "68/68 [==============================] - 256s 4s/step - loss: 1.9051 - accuracy: 0.2994 - mae: 0.4441 - val_loss: 1.7822 - val_accuracy: 0.6403 - val_mae: 0.4270\n",
            "Epoch 7/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.8095 - accuracy: 0.3227 - mae: 0.4408\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [16.1, 16.7, 16.1, 17.0, 18.9, 19.9] [18.1, 19.2, 18.0, 19.1, 17.2, 18.6] PM [17.1, 18.0, 17.1, 18.05, 18.1, 19.25] R [70.8, 50.6, 43.1, 33.3, 20.2, 10.9] [71.8, 50.9, 43.3, 33.3, 19.8, 11.2]\n",
            "68/68 [==============================] - 256s 4s/step - loss: 1.8095 - accuracy: 0.3227 - mae: 0.4408 - val_loss: 1.7241 - val_accuracy: 0.4626 - val_mae: 0.4326\n",
            "Epoch 8/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.7267 - accuracy: 0.2963 - mae: 0.4409\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [18.5, 17.7, 16.6, 16.6, 20.0, 21.9] [20.7, 21.0, 21.6, 23.1, 24.1, 24.6] PM [19.6, 19.35, 19.15, 19.9, 22.05, 23.3] R [70.6, 51.7, 45.0, 35.6, 22.7, 13.4] [72.1, 52.8, 45.9, 36.9, 23.4, 13.9]\n",
            "68/68 [==============================] - 251s 4s/step - loss: 1.7267 - accuracy: 0.2963 - mae: 0.4409 - val_loss: 1.6641 - val_accuracy: 0.3674 - val_mae: 0.4341\n",
            "Epoch 9/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.6589 - accuracy: 0.3311 - mae: 0.4376\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [16.8, 17.2, 17.9, 18.4, 18.6, 21.1] [18.1, 19.1, 19.2, 19.2, 18.4, 20.1] PM [17.45, 18.15, 18.55, 18.85, 18.55, 20.65] R [74.4, 55.6, 48.6, 38.9, 25.1, 14.9] [75.1, 55.6, 48.6, 39.1, 24.7, 14.7]\n",
            "68/68 [==============================] - 255s 4s/step - loss: 1.6589 - accuracy: 0.3311 - mae: 0.4376 - val_loss: 1.6071 - val_accuracy: 0.3562 - val_mae: 0.4345\n",
            "Epoch 10/10\n",
            "68/68 [==============================] - ETA: 0s - loss: 1.6016 - accuracy: 0.2936 - mae: 0.4400\n",
            "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [17.5, 17.8, 18.7, 19.4, 21.0, 23.9] [18.5, 19.9, 20.1, 20.8, 19.9, 20.5] PM [18.0, 18.85, 19.45, 20.1, 20.45, 22.25] R [73.9, 55.2, 48.4, 38.6, 25.1, 14.7] [74.5, 55.8, 48.7, 39.0, 25.2, 14.9]\n",
            "68/68 [==============================] - 254s 4s/step - loss: 1.6016 - accuracy: 0.2936 - mae: 0.4400 - val_loss: 1.6222 - val_accuracy: 0.1730 - val_mae: 0.4479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check std= [0, 0.5, 0.7, 1, 1.5, 2] P [12.5, 11.5, 11.3, 9.4, 7.2, 9.8] [19.7, 19.8, 19.6, 17.7, 15.9, 13.6] PM [16.1, 15.65, 15.5, 13.55, 11.6, 11.7] R [67.2, 47.0, 39.5, 29.9, 17.4, 9.3] [68.2, 47.3, 39.7, 30.2, 18.0, 9.8]\n",
        "\n",
        "Check std - Границы классификации\n",
        "\n",
        "P - Доходность на тестовой и валидационной\n",
        "\n",
        "PM - Средняя доходность тестовой и валидационной\n",
        "\n",
        "R - Рекал"
      ],
      "metadata": {
        "id": "x3Js0qN29c5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnqVHZxc6SvL",
        "outputId": "b00429b0-f3da-42dc-cf70-bc7570823948"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 32, 9)]           0         \n",
            "                                                                 \n",
            " dbl_104 (DBL)               (None, 32, 8)             248       \n",
            "                                                                 \n",
            " res_block_10 (ResBlock)     (None, 16, 16)            1056      \n",
            "                                                                 \n",
            " res_block_11 (ResBlock)     (None, 8, 32)             6144      \n",
            "                                                                 \n",
            " res_block_12 (ResBlock)     (None, 4, 64)             75008     \n",
            "                                                                 \n",
            " res_block_13 (ResBlock)     (None, 2, 128)            293376    \n",
            "                                                                 \n",
            " res_block_14 (ResBlock)     (None, 1, 256)            629760    \n",
            "                                                                 \n",
            " flatten_28 (Flatten)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 20)                5140      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 3)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,010,795\n",
            "Trainable params: 1,001,867\n",
            "Non-trainable params: 8,928\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}